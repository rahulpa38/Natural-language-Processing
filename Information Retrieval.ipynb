{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP Assignment-4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "jyQV_VmbXsCg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2354f1e1-e3c4-4345-d55c-0885ac1e951c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8oEcNyAwXtw9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"/content/drive/My Drive/tweets_corpus.txt\",mode = 'r') as f:\n",
        "  file_text = f.read()\n",
        "# lines = file_text.readline()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stjhvzU_E6_C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lines = file_text.split('\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7HwMV4W6FgKV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "5495a3f2-a64b-4285-8ff9-ad9edd33c0e3"
      },
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords \n",
        "from nltk.tokenize import word_tokenize \n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer \n",
        "import collections\n",
        "from collections import OrderedDict\n",
        "ord_dict = collections.OrderedDict()\n",
        "lemmatizer = WordNetLemmatizer() \n",
        "  \n",
        "nltk.download('stopwords')\n",
        "\n",
        "stop_words = set(stopwords.words('english')) "
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_mSXwcVMMYnc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "from nltk.stem import PorterStemmer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGy8a7XlE8gu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "doc_ids = []\n",
        "inverted_index = {}\n",
        "total_text = ''\n",
        "ps = PorterStemmer()\n",
        "no_of_documents = 0\n",
        "word_count = []\n",
        "for line in lines:\n",
        "  ## split Doc id and tweet \n",
        "  tweet = line.split('\\t')\n",
        "  \n",
        "  if len(tweet) > 1:\n",
        "    no_of_documents += 1\n",
        "    doc_ids.append(tweet[0])\n",
        "    ## lowercase the string \n",
        "    text_lower = tweet[1].lower()\n",
        "    ## take only words\n",
        "    text_lower = re.sub(r'[^\\w]', ' ', text_lower)\n",
        "    ## split the text \n",
        "    word_splt = text_lower.split()\n",
        "    ## tokenize the word \n",
        "    word_tokeniz = []\n",
        "    for word in word_splt:\n",
        "       word_tokeniz.append(word) \n",
        "    ## Remove stop words\n",
        "    wrd_stp = [w for w in word_tokeniz if not w in stop_words]\n",
        "    ## Lemmatize word\n",
        "    word_count.append(len(wrd_stp))\n",
        "    for word in wrd_stp:\n",
        "      stem_word = ps.stem(word)\n",
        "      ## Only Take words > 2 length \n",
        "      if len(stem_word) > 1:\n",
        "        if stem_word in inverted_index:\n",
        "          ## create a dictionary with key as word and value as document id \n",
        "          inverted_index[stem_word].append(tweet[0])\n",
        "        else:\n",
        "          inverted_index[stem_word] = [tweet[0]]\n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TnfuZBNNHUHX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from copy import deepcopy as deepcopy\n",
        "inverted_index1 = deepcopy(inverted_index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENPDaA70HZHH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for key,value in inverted_index.items():\n",
        "  # if key == 'chocol':\n",
        "  #   print(inverted_index1[key])\n",
        "  inverted_index[key] = sorted(list(set(value)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWGjNOjs9a7l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "import numpy as np\n",
        "tf_idf_word = {}\n",
        "for word in list(inverted_index.keys()):\n",
        "  tf_idf_word[word] = np.zeros((no_of_documents,))\n",
        "  for i,doc_id in enumerate(doc_ids):\n",
        "    word_tf = inverted_index1[word].count(doc_id)/word_count[i]\n",
        "    word_idf = math.log10(no_of_documents/len(inverted_index[word]))\n",
        "    tf_idf_word[word][i] = word_tf*word_idf\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rCh8O4RaI5lC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "150951ec-7b29-4684-edd0-91f0808f763e"
      },
      "source": [
        "len(inverted_index['chocol'])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCSYqL4ABThU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "5e062530-227d-4976-aba4-d2bccb8828c3"
      },
      "source": [
        "tf_idf_word['chocol']"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.19621477, 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.10791812, 0.        ])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TeTZYtN-t2o9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def merging_doc(doc_id1,doc_id2,signal):\n",
        "  count1 = 0\n",
        "  count2 = 0\n",
        "  merged_ids = []\n",
        "  ## merge part\n",
        "  while count1 < len(doc_id1) and count2 < len(doc_id2):\n",
        "      if doc_id1[count1] < doc_id2[count2]:\n",
        "        ## if 'OR' in query then only add this document id \n",
        "        ## else in intersection we only increment the counter\n",
        "        if signal == 'union':\n",
        "          merged_ids.append(doc_id1[count1])\n",
        "        ## increment the counter of first document \n",
        "        count1 = count1 + 1\n",
        "      elif doc_id1[count1] == doc_id2[count2]:\n",
        "        ## if both the document ids are equal \n",
        "        ## then increment both the counters of the document ids \n",
        "        merged_ids.append(doc_id1[count1])\n",
        "        count1 = count1 + 1\n",
        "        count2 = count2 + 1\n",
        "      else:\n",
        "        ## if 'OR' in query then only add this document id \n",
        "        ## else in intersection we only increment the counter\n",
        "        if signal == 'union':\n",
        "          merged_ids.append(doc_id2[count2])\n",
        "        ## increment the counter of second document \n",
        "        count2 = count2 + 1\n",
        "  print(\"Merged them\", merged_ids)\n",
        "  return merged_ids"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZlvY7uJHbC1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def merge_algorithm(query):\n",
        "\n",
        "\n",
        "  tf_ifds_query = np.zeros((no_of_documents,))\n",
        "\n",
        "## Lower the query part\n",
        "  query = query.lower()\n",
        "  ## Split the query\n",
        "  query = query.split()\n",
        "  query_splt = []\n",
        "  for word in query:\n",
        "    query_splt.append(ps.stem(word))\n",
        "\n",
        "## Stemm the query part\n",
        "  print(\"Stemmed_words \" ,query_splt)\n",
        "  store_qw_freq = {}\n",
        "\n",
        "\n",
        "  sorted_terms = []\n",
        "  ## If only 'AND' or 'OR' part is used in the query part\n",
        "  ## Using the ------------------------Restrictive Model------------ in th 'IF' part\n",
        "  ## creating word - len(posting) dictionary\n",
        "  if ('and' not in query_splt) or ('or' not in query_splt):\n",
        "    for i in range(len(query_splt)):\n",
        "      if i%2 == 0:\n",
        "        if query_splt[i] in inverted_index:\n",
        "          \n",
        "          store_qw_freq[query_splt[i]] = len(inverted_index[query_splt[i]])\n",
        "    \n",
        "\n",
        "## sorting the dictionary by value\n",
        "    print(\" Store qw freq\", store_qw_freq)\n",
        "    sorted_terms1 = sorted(store_qw_freq.items(), key=lambda kv: kv[1])\n",
        "\n",
        "    len_sorted_terms = len(sorted_terms1)\n",
        "    for l,values in enumerate(sorted_terms1):\n",
        "      if ('and' not in query_splt):\n",
        "        sorted_terms.append(values[0])\n",
        "        if l != len_sorted_terms - 1:\n",
        "          sorted_terms.append('or')\n",
        "      if ('or' not in query_splt):\n",
        "        sorted_terms.append(values[0])\n",
        "        if l != len_sorted_terms - 1:\n",
        "          sorted_terms.append('and')\n",
        "    print(\"Sorted Terms\",sorted_terms)\n",
        " ## If the query contains 'AND' and 'OR' part then go by sequence \n",
        "  else:\n",
        "    for i in range(len(query_splt)):\n",
        "        sorted_terms.append(query_splt[i])\n",
        "\n",
        "\n",
        "  print(\"Sorted_terms\" ,sorted_terms)\n",
        "\n",
        "  merged_ids = []\n",
        "  # count = 0\n",
        "  doc_id1 = []\n",
        "  doc_id2 = []\n",
        "\n",
        "  ## Loop on all the terms of the query\n",
        "  for i,word in enumerate(sorted_terms):\n",
        "    ## if first word is empty then fill it \n",
        "    if doc_id1 == [] and (word != 'and' and word != 'or'):\n",
        "      print (\"Inside doc_id1 \",word)\n",
        "    ## if word exist in inverted index\n",
        "      if word in inverted_index:\n",
        "        doc_id1 = inverted_index[word]\n",
        "        print(word,\"-\", doc_id1)\n",
        "    ## if second word exist is empty then fill it \n",
        "    elif doc_id2 == [] and (word != 'and' and word != 'or'):\n",
        "      print (\"Inside doc_id2 \",word)\n",
        "      if word in inverted_index:\n",
        "        doc_id2 = inverted_index[word]  \n",
        "        print(word,\"-\", doc_id2)\n",
        "    ## if first and second word are there then merge them\n",
        "    if doc_id1 and doc_id2 and (word != 'and' and word != 'or'):\n",
        "      ## use 'AND'\n",
        "      if sorted_terms[i-1] == 'and':\n",
        "        print(\"Taking Intersection\", query_splt[i], query_splt[i-2])\n",
        "        merged_ids = merging_doc(doc_id1,doc_id2,'intersection')\n",
        "        ## Doing tf-idf part\n",
        "        for d,document_id in enumerate(doc_ids):\n",
        "          tf_ifds_query[d] = tf_idf_word[query_splt[i]][d]* tf_idf_word[query_splt[i - 2]][d]\n",
        "      ## use 'OR'\n",
        "      elif sorted_terms[i-1] == 'or':\n",
        "        print(\"Taking Union\", query_splt[i], query_splt[i-2])\n",
        "        merged_ids = merging_doc(doc_id1,doc_id2,'union')\n",
        "        for d,document_id in enumerate(doc_ids):\n",
        "          tf_ifds_query[d] = tf_idf_word[query_splt[i]][d] + tf_idf_word[query_splt[i - 2]][d]\n",
        "      doc_id1 = merged_ids\n",
        "      doc_id2 = []\n",
        "        \n",
        "  print(\"Final Merged Ids\",merged_ids)\n",
        "  return tf_ifds_query"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zhy-xUaeRWVd",
        "colab_type": "text"
      },
      "source": [
        "egg AND cheese\n",
        "\n",
        "chocolate AND strawberry\n",
        "\n",
        "eggs AND cheese AND bacon AND chocolate\n",
        "\n",
        "chocolate OR strawberry OR eggs OR bacon\n",
        "\n",
        "eggs AND cheese OR strawberry AND chocolate\n",
        "\n",
        "(eggs AND cheese) OR (eggs AND bacon)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sEt_97jnRpLK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "outputId": "eedfbf3d-b8a8-41a9-aadc-74aed8861aca"
      },
      "source": [
        "tf_idfs_query = merge_algorithm('eggs AND cheese OR strawberry AND chocolate or sum')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Stemmed_words  ['egg', 'and', 'chees', 'or', 'strawberri', 'and', 'chocol', 'or', 'sum']\n",
            "Sorted_terms ['egg', 'and', 'chees', 'or', 'strawberri', 'and', 'chocol', 'or', 'sum']\n",
            "Inside doc_id1  egg\n",
            "egg - ['81503002321616896', '81587643376336896', '81673244926685184', '81736742478155778', '82650970722533376', '85032815321825280', '86441828815089664']\n",
            "Inside doc_id2  chees\n",
            "chees - ['81503002321616896', '81507775422791680', '81534165975171072', '81535634019323904', '81577509950459904', '81582996083326976', '81587643376336896', '81673244926685184', '81736742478155778', '82650970722533376', '85032815321825280', '85094773555335168', '86441828815089664']\n",
            "Taking Intersection chees egg\n",
            "Merged them ['81503002321616896', '81587643376336896', '81673244926685184', '81736742478155778', '82650970722533376', '85032815321825280', '86441828815089664']\n",
            "Inside doc_id2  strawberri\n",
            "strawberri - ['81500716438523904', '81623945064890368', '81656304107651072', '81715158593966080', '81716618236928000', '81842384404623360', '81844590625304576', '82461950231064576', '85032815321825280', '85094773555335168']\n",
            "Taking Union strawberri chees\n",
            "Merged them ['81500716438523904', '81503002321616896', '81587643376336896', '81623945064890368', '81656304107651072', '81673244926685184', '81715158593966080', '81716618236928000', '81736742478155778', '81842384404623360', '81844590625304576', '82461950231064576', '82650970722533376', '85032815321825280', '85094773555335168']\n",
            "Inside doc_id2  chocol\n",
            "chocol - ['81656304107651072', '85094773555335168']\n",
            "Taking Intersection chocol strawberri\n",
            "Merged them ['81656304107651072', '85094773555335168']\n",
            "Inside doc_id2  sum\n",
            "sum - ['86441828815089664']\n",
            "Taking Union sum chocol\n",
            "Merged them ['81656304107651072', '85094773555335168']\n",
            "Final Merged Ids ['81656304107651072', '85094773555335168']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ndtA9NOldWf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "outputId": "4238d467-2ba5-41ee-9144-55c01fb39b1e"
      },
      "source": [
        "sum_of_tf_idf_doc_id = 0\n",
        "## print tfids sum\n",
        "for i,document_d in enumerate(doc_ids):\n",
        "  print(document_d,\" - \", tf_idfs_query[i])\n",
        "  sum_of_tf_idf_doc_id += tf_idfs_query[i]\n",
        "\n",
        "print(\"\\n\\n\\nSum of Tf Idf is \",sum_of_tf_idf_doc_id)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "81499877556760576  -  0.0\n",
            "81500716438523904  -  0.0\n",
            "81503002321616896  -  0.0\n",
            "81507775422791680  -  0.0\n",
            "81534165975171072  -  0.0\n",
            "81535634019323904  -  0.0\n",
            "81577509950459904  -  0.0\n",
            "81582996083326976  -  0.0\n",
            "81587643376336896  -  0.0\n",
            "81600113016971264  -  0.0\n",
            "81623945064890368  -  0.0\n",
            "81644157432643584  -  0.0\n",
            "81656304107651072  -  0.19621477200865908\n",
            "81673244926685184  -  0.0\n",
            "81715158593966080  -  0.0\n",
            "81716618236928000  -  0.0\n",
            "81736742478155778  -  0.0\n",
            "81842384404623360  -  0.0\n",
            "81844590625304576  -  0.0\n",
            "82461950231064576  -  0.0\n",
            "82650970722533376  -  0.0\n",
            "85032815321825280  -  0.0\n",
            "85094773555335168  -  0.1079181246047625\n",
            "86441828815089664  -  0.08118889657127093\n",
            "\n",
            "\n",
            "\n",
            "Sum of Tf Idf is  0.3853217931846925\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqAY9oBkHpU-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "0990f2c7-5583-4798-b4ee-a9965b42fecc"
      },
      "source": [
        "tf_idfs_query = merge_algorithm('eggs AND cheese')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Stemmed_words  ['egg', 'and', 'chees']\n",
            " Store qw freq {'egg': 7, 'chees': 13}\n",
            "Sorted Terms ['egg', 'and', 'chees']\n",
            "Sorted_terms ['egg', 'and', 'chees']\n",
            "Inside doc_id1  egg\n",
            "egg - ['81503002321616896', '81587643376336896', '81673244926685184', '81736742478155778', '82650970722533376', '85032815321825280', '86441828815089664']\n",
            "Inside doc_id2  chees\n",
            "chees - ['81503002321616896', '81507775422791680', '81534165975171072', '81535634019323904', '81577509950459904', '81582996083326976', '81587643376336896', '81673244926685184', '81736742478155778', '82650970722533376', '85032815321825280', '85094773555335168', '86441828815089664']\n",
            "Taking Intersection chees egg\n",
            "Merged them ['81503002321616896', '81587643376336896', '81673244926685184', '81736742478155778', '82650970722533376', '85032815321825280', '86441828815089664']\n",
            "Final Merged Ids ['81503002321616896', '81587643376336896', '81673244926685184', '81736742478155778', '82650970722533376', '85032815321825280', '86441828815089664']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "alSV_ttwsXfd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "outputId": "c6ccdf12-7d03-48ba-ff08-9f489cc07028"
      },
      "source": [
        "sum_of_tf_idf_doc_id = 0\n",
        "## print tfids sum\n",
        "for i,document_d in enumerate(doc_ids):\n",
        "  print(document_d,\" - \", tf_idfs_query[i])\n",
        "  sum_of_tf_idf_doc_id += tf_idfs_query[i]\n",
        "\n",
        "print(\"\\n\\n\\nSum of Tf Idf is \",sum_of_tf_idf_doc_id)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "81499877556760576  -  0.0\n",
            "81500716438523904  -  0.0\n",
            "81503002321616896  -  0.0005565760265960224\n",
            "81507775422791680  -  0.0\n",
            "81534165975171072  -  0.0\n",
            "81535634019323904  -  0.0\n",
            "81577509950459904  -  0.0\n",
            "81582996083326976  -  0.0\n",
            "81587643376336896  -  0.0022263041063840896\n",
            "81600113016971264  -  0.0\n",
            "81623945064890368  -  0.0\n",
            "81644157432643584  -  0.0\n",
            "81656304107651072  -  0.0\n",
            "81673244926685184  -  0.0011775492794097665\n",
            "81715158593966080  -  0.0\n",
            "81716618236928000  -  0.0\n",
            "81736742478155778  -  0.003957873966905048\n",
            "81842384404623360  -  0.0\n",
            "81844590625304576  -  0.0\n",
            "82461950231064576  -  0.0\n",
            "82650970722533376  -  0.000726956442900927\n",
            "85032815321825280  -  0.0006332598347048076\n",
            "85094773555335168  -  0.0\n",
            "86441828815089664  -  0.0004930223626594524\n",
            "\n",
            "\n",
            "\n",
            "Sum of Tf Idf is  0.009771542019560113\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSqI8eJQsb77",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "outputId": "04e91f28-79e4-4175-ee1b-78d55f023add"
      },
      "source": [
        "tf_idfs_query = merge_algorithm('chocolate OR strawberry OR eggs OR bacon')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Stemmed_words  ['chocol', 'or', 'strawberri', 'or', 'egg', 'or', 'bacon']\n",
            " Store qw freq {'chocol': 2, 'strawberri': 10, 'egg': 7, 'bacon': 5}\n",
            "Sorted Terms ['chocol', 'or', 'bacon', 'or', 'egg', 'or', 'strawberri']\n",
            "Sorted_terms ['chocol', 'or', 'bacon', 'or', 'egg', 'or', 'strawberri']\n",
            "Inside doc_id1  chocol\n",
            "chocol - ['81656304107651072', '85094773555335168']\n",
            "Inside doc_id2  bacon\n",
            "bacon - ['81503002321616896', '81736742478155778', '82650970722533376', '85032815321825280', '86441828815089664']\n",
            "Taking Union strawberri chocol\n",
            "Merged them ['81503002321616896', '81656304107651072', '81736742478155778', '82650970722533376', '85032815321825280', '85094773555335168']\n",
            "Inside doc_id2  egg\n",
            "egg - ['81503002321616896', '81587643376336896', '81673244926685184', '81736742478155778', '82650970722533376', '85032815321825280', '86441828815089664']\n",
            "Taking Union egg strawberri\n",
            "Merged them ['81503002321616896', '81587643376336896', '81656304107651072', '81673244926685184', '81736742478155778', '82650970722533376', '85032815321825280', '85094773555335168']\n",
            "Inside doc_id2  strawberri\n",
            "strawberri - ['81500716438523904', '81623945064890368', '81656304107651072', '81715158593966080', '81716618236928000', '81842384404623360', '81844590625304576', '82461950231064576', '85032815321825280', '85094773555335168']\n",
            "Taking Union bacon egg\n",
            "Merged them ['81500716438523904', '81503002321616896', '81587643376336896', '81623945064890368', '81656304107651072', '81673244926685184', '81715158593966080', '81716618236928000', '81736742478155778', '81842384404623360', '81844590625304576', '82461950231064576', '82650970722533376', '85032815321825280', '85094773555335168']\n",
            "Final Merged Ids ['81500716438523904', '81503002321616896', '81587643376336896', '81623945064890368', '81656304107651072', '81673244926685184', '81715158593966080', '81716618236928000', '81736742478155778', '81842384404623360', '81844590625304576', '82461950231064576', '82650970722533376', '85032815321825280', '85094773555335168']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDW_bwuU2nc8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "outputId": "b85b8776-47da-4417-8c63-ee3a4d6f55dd"
      },
      "source": [
        "sum_of_tf_idf_doc_id = 0\n",
        "## print tfids sum\n",
        "for i,document_d in enumerate(doc_ids):\n",
        "  print(document_d,\" - \", tf_idfs_query[i])\n",
        "  sum_of_tf_idf_doc_id += tf_idfs_query[i]\n",
        "\n",
        "print(\"\\n\\n\\nSum of Tf Idf is \",sum_of_tf_idf_doc_id)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "81499877556760576  -  0.0\n",
            "81500716438523904  -  0.0\n",
            "81503002321616896  -  0.07602215244205851\n",
            "81507775422791680  -  0.0\n",
            "81534165975171072  -  0.0\n",
            "81535634019323904  -  0.0\n",
            "81577509950459904  -  0.0\n",
            "81582996083326976  -  0.0\n",
            "81587643376336896  -  0.06688915021216864\n",
            "81600113016971264  -  0.0\n",
            "81623945064890368  -  0.0\n",
            "81644157432643584  -  0.0\n",
            "81656304107651072  -  0.0\n",
            "81673244926685184  -  0.04864665469975901\n",
            "81715158593966080  -  0.0\n",
            "81716618236928000  -  0.0\n",
            "81736742478155778  -  0.20272573984548936\n",
            "81842384404623360  -  0.0\n",
            "81844590625304576  -  0.0\n",
            "82461950231064576  -  0.0\n",
            "82650970722533376  -  0.08688245993378116\n",
            "85032815321825280  -  0.08109029593819575\n",
            "85094773555335168  -  0.0\n",
            "86441828815089664  -  0.07155026112193744\n",
            "\n",
            "\n",
            "\n",
            "Sum of Tf Idf is  0.6338067141933899\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MtDfRqiQ2qMs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "outputId": "709c9a82-a468-4824-8077-8fd218fafe95"
      },
      "source": [
        "tf_idfs_query = merge_algorithm('eggs AND cheese OR strawberry AND chocolate')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Stemmed_words  ['egg', 'and', 'chees', 'or', 'strawberri', 'and', 'chocol']\n",
            "Sorted_terms ['egg', 'and', 'chees', 'or', 'strawberri', 'and', 'chocol']\n",
            "Inside doc_id1  egg\n",
            "egg - ['81503002321616896', '81587643376336896', '81673244926685184', '81736742478155778', '82650970722533376', '85032815321825280', '86441828815089664']\n",
            "Inside doc_id2  chees\n",
            "chees - ['81503002321616896', '81507775422791680', '81534165975171072', '81535634019323904', '81577509950459904', '81582996083326976', '81587643376336896', '81673244926685184', '81736742478155778', '82650970722533376', '85032815321825280', '85094773555335168', '86441828815089664']\n",
            "Taking Intersection chees egg\n",
            "Merged them ['81503002321616896', '81587643376336896', '81673244926685184', '81736742478155778', '82650970722533376', '85032815321825280', '86441828815089664']\n",
            "Inside doc_id2  strawberri\n",
            "strawberri - ['81500716438523904', '81623945064890368', '81656304107651072', '81715158593966080', '81716618236928000', '81842384404623360', '81844590625304576', '82461950231064576', '85032815321825280', '85094773555335168']\n",
            "Taking Union strawberri chees\n",
            "Merged them ['81500716438523904', '81503002321616896', '81587643376336896', '81623945064890368', '81656304107651072', '81673244926685184', '81715158593966080', '81716618236928000', '81736742478155778', '81842384404623360', '81844590625304576', '82461950231064576', '82650970722533376', '85032815321825280', '85094773555335168']\n",
            "Inside doc_id2  chocol\n",
            "chocol - ['81656304107651072', '85094773555335168']\n",
            "Taking Intersection chocol strawberri\n",
            "Merged them ['81656304107651072', '85094773555335168']\n",
            "Final Merged Ids ['81656304107651072', '85094773555335168']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyGjvfsW247j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "outputId": "c1399fc8-3052-4b6f-8029-ec9c03162459"
      },
      "source": [
        "sum_of_tf_idf_doc_id = 0\n",
        "## print tfids sum\n",
        "for i,document_d in enumerate(doc_ids):\n",
        "  print(document_d,\" - \", tf_idfs_query[i])\n",
        "  sum_of_tf_idf_doc_id += tf_idfs_query[i]\n",
        "\n",
        "print(\"\\n\\n\\nSum of Tf Idf is \",sum_of_tf_idf_doc_id)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "81499877556760576  -  0.0\n",
            "81500716438523904  -  0.0\n",
            "81503002321616896  -  0.0\n",
            "81507775422791680  -  0.0\n",
            "81534165975171072  -  0.0\n",
            "81535634019323904  -  0.0\n",
            "81577509950459904  -  0.0\n",
            "81582996083326976  -  0.0\n",
            "81587643376336896  -  0.0\n",
            "81600113016971264  -  0.0\n",
            "81623945064890368  -  0.0\n",
            "81644157432643584  -  0.0\n",
            "81656304107651072  -  0.006782096555233813\n",
            "81673244926685184  -  0.0\n",
            "81715158593966080  -  0.0\n",
            "81716618236928000  -  0.0\n",
            "81736742478155778  -  0.0\n",
            "81842384404623360  -  0.0\n",
            "81844590625304576  -  0.0\n",
            "82461950231064576  -  0.0\n",
            "82650970722533376  -  0.0\n",
            "85032815321825280  -  0.0\n",
            "85094773555335168  -  0.0041031684159164574\n",
            "86441828815089664  -  0.0\n",
            "\n",
            "\n",
            "\n",
            "Sum of Tf Idf is  0.01088526497115027\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gl1-up8M26w2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}